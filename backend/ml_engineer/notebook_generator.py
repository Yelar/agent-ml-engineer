"""
Jupyter notebook generator from execution history
"""

import json
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime


class NotebookGenerator:
    """Generate Jupyter notebooks from execution history"""

    def __init__(self):
        self.cells = []

    def add_markdown_cell(self, content: str):
        """Add a markdown cell to the notebook"""
        self.cells.append({
            "cell_type": "markdown",
            "metadata": {},
            "source": content.split('\n')
        })

    def add_code_cell(self, code: str, outputs: List[Dict] = None):
        """Add a code cell to the notebook"""
        cell = {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": code.split('\n'),
            "outputs": outputs or []
        }
        self.cells.append(cell)

    def create_output(self, text: str = None, image_base64: str = None) -> Dict:
        """Create an output object for a code cell"""
        if image_base64:
            return {
                "output_type": "display_data",
                "data": {
                    "image/png": image_base64
                },
                "metadata": {}
            }
        elif text:
            return {
                "output_type": "stream",
                "name": "stdout",
                "text": text.split('\n')
            }
        return {}

    def generate_from_execution_history(
        self,
        execution_history: List[Dict[str, Any]],
        dataset_name: str,
        user_prompt: str,
        solution: str = None
    ) -> dict:
        """
        Generate a Jupyter notebook from execution history

        Args:
            execution_history: List of execution results
            dataset_name: Name of the dataset
            user_prompt: Original user prompt
            solution: Final solution text

        Returns:
            Jupyter notebook as a dictionary
        """
        # Clear cells
        self.cells = []

        # Add title and introduction
        self.add_markdown_cell(f"""# ML Pipeline: {dataset_name}

**Generated by ML Engineer Agent**
**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Objective
{user_prompt}
""")

        # Add setup cell
        self.add_markdown_cell("## Setup\nImport required libraries and load the dataset.")

        setup_code = """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Set plotting style
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
"""
        self.add_code_cell(setup_code)

        # Add data loading
        self.add_markdown_cell("## Load Dataset")
        # Note: We can't include the actual path in the notebook, so use a placeholder
        load_code = f"""# Load the dataset
# Note: Update the path to your dataset location
df = pd.read_csv('{dataset_name}.csv')
print(f"Dataset shape: {{df.shape}}")
df.head()"""
        self.add_code_cell(load_code)

        # Process execution history
        section_counter = 1
        for i, execution in enumerate(execution_history):
            if not execution.get('success', False):
                continue

            code = execution.get('code', '').strip()
            if not code:
                continue

            # Try to infer section name from code
            section_name = self._infer_section_name(code, section_counter)

            # Add section header
            self.add_markdown_cell(f"## {section_name}")

            # Create outputs
            outputs = []

            # Add text output if available
            if execution.get('output'):
                outputs.append(self.create_output(text=execution['output']))

            # Add plots if available
            for plot_base64 in execution.get('plots', []):
                outputs.append(self.create_output(image_base64=plot_base64))

            # Add the code cell with outputs
            self.add_code_cell(code, outputs)

            section_counter += 1

        # Add solution/summary if available
        if solution:
            self.add_markdown_cell(f"""## Summary and Results

{solution}
""")

        # Add conclusion
        self.add_markdown_cell("""## Conclusion

This notebook contains the complete ML pipeline generated by the ML Engineer Agent.
You can run all cells to reproduce the analysis, or modify them to explore further.

### Next Steps
- Review and validate the results
- Fine-tune model parameters
- Try different algorithms
- Deploy the model to production
""")

        # Create notebook structure
        notebook = {
            "cells": self.cells,
            "metadata": {
                "kernelspec": {
                    "display_name": "Python 3",
                    "language": "python",
                    "name": "python3"
                },
                "language_info": {
                    "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                    },
                    "file_extension": ".py",
                    "mimetype": "text/x-python",
                    "name": "python",
                    "nbconvert_exporter": "python",
                    "pygments_lexer": "ipython3",
                    "version": "3.9.0"
                }
            },
            "nbformat": 4,
            "nbformat_minor": 5
        }

        return notebook

    def _infer_section_name(self, code: str, counter: int) -> str:
        """Infer a section name from the code"""
        code_lower = code.lower()

        # Keywords to section names
        patterns = [
            (['info()', 'describe()', 'dtypes', 'shape'], 'Data Exploration'),
            (['isnull', 'isna', 'missing', 'fillna', 'dropna'], 'Missing Value Analysis'),
            (['plot', 'plt.', 'sns.', 'histogram', 'scatter', 'boxplot'], 'Data Visualization'),
            (['corr()', 'correlation', 'heatmap'], 'Correlation Analysis'),
            (['train_test_split', 'split'], 'Train-Test Split'),
            (['scaler', 'standardscaler', 'normalize', 'scale'], 'Feature Scaling'),
            (['fit(', 'model.', 'classifier', 'regressor'], 'Model Training'),
            (['predict(', 'prediction'], 'Model Prediction'),
            (['score', 'accuracy', 'precision', 'recall', 'f1', 'mse', 'rmse', 'r2'], 'Model Evaluation'),
            (['feature_importances', 'coefficients'], 'Feature Importance'),
        ]

        for keywords, section in patterns:
            if any(keyword in code_lower for keyword in keywords):
                return section

        return f"Step {counter}"

    def save(self, notebook: dict, output_path: str):
        """Save the notebook to a file"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(notebook, f, indent=2, ensure_ascii=False)


def generate_notebook(
    execution_history: List[Dict[str, Any]],
    dataset_name: str,
    user_prompt: str,
    output_path: str,
    solution: str = None
) -> str:
    """
    Convenience function to generate and save a notebook

    Args:
        execution_history: List of execution results
        dataset_name: Name of the dataset
        user_prompt: Original user prompt
        output_path: Path to save the notebook
        solution: Final solution text

    Returns:
        Path to the saved notebook
    """
    generator = NotebookGenerator()
    notebook = generator.generate_from_execution_history(
        execution_history=execution_history,
        dataset_name=dataset_name,
        user_prompt=user_prompt,
        solution=solution
    )

    # Ensure output directory exists
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)

    generator.save(notebook, output_path)
    return output_path
